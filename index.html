

<!doctype html>
<html>

<head>


<title>Keji He</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Zhe Li, 李哲"> 
<meta name="description" content="Zhe Li's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />

<script>
   function showPubs(id) {
  if (id == 0) {
    document.getElementById('pubs').innerHTML = document.getElementById('pubs_selected').innerHTML;
    document.getElementById('select0').style = 'text-decoration:underline;color:#000000';
    document.getElementById('select1').style = '';
  } else {
    document.getElementById('pubs').innerHTML = document.getElementById('pubs_by_topic').innerHTML;
    document.getElementById('select1').style = 'text-decoration:underline;color:#000000';
    document.getElementById('select0').style = '';
  }
}

</script>

</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Zhe Li 李哲<h1>
				</div>

                <h3>Ph.D. candidate</h3>

		<p>
                    School of Cyber Science and Technology </br>
                    University of Science and Technology of China </br>
					</br>
                    Email: lizhe777@mail.ustc.edu.cn </br>
		</p>
		<p>
			<!-- <a href="https://github.com/hongyuanyu"><img src="assets/logos/github_logo.png" height="30px"></a>&nbsp;&nbsp; -->
			<a href="https://scholar.google.com/citations?user=Xc9m54IAAAAJ&hl=zh-CN"><img src="assets/logos/google_logo.png" height="30px"></a>&nbsp;&nbsp;
			<!-- <a href="https://www.linkedin.com/in/hongyuan-yu-726126178/"><img src="assets/logos/linkedin_logo.png" height="30px"></a>&nbsp;&nbsp; -->
		</p>
			</td>

			</td>
			<td width="25%">
				<img src="assets/imgs/keji2.jpg" width="80%"/>
			</td>
		<tr>
	</tbody>
</table>

<h2>News</h2>
<ul>   
<li> <p>2025.07, Our survey about the ***composed image retrieval*** is now available on <a href='https://arxiv.org/pdf/2503.01334'> arXiv</a> and is undergoing final revisions.</a> </p></li> 
<li> <p>2025.06, I graduated from USTC! </a> </p></li> 
<li> <p>2025.06, One paper was accepted to ICCV 2025. </a> </p></li> 
<li> <p>2025.04, One paper was accepted to SIGIR 2025. </a> </p></li> 
<li> <p>2025.06, One paper was accepted to CVPR 2025. </a> </p></li> 
<li> <p>2025.06, Two papers were accepted to IEEE TCSVT. </a> </p></li> 
<li> <p>2025.06, One paper was accepted to IEEE TCSVT. </a> </p></li> 
<li> <p>2025.06, One paper was accepted to Nature Nanotechnology. </a> </p></li> 
<li> <p>2025.06, One paper was accepted to IEEE TETCI. </a> </p></li> 
<li> <p>2025.06, I went to the Institute of Automation at the Chinese Academy of Sciences in Beijing for a research visit. </a> </p></li> 
</ul>

<h2>Biography</h2> 
<p>
Dr. Keji He is an assistant professor at the School of Artificial Intelligence, Shandong University (SDU). He finished his PhD at the Institute of Automation, Chinese Academy of Sciences, supervised by Prof. <a href="https://scholar.google.com/citations?user=8kzzUboAAAAJ&hl=zh-CN">Liang Wang</a>  (IEEE Fellow) and Prof. <a href="https://yanrockhuang.github.io/">Yan Huang</a>. He is also a jointly PhD at the National University of Singapore (NUS), supervised by Prof. <a href="https://scholar.google.com/citations?user=w69Buq0AAAAJ&hl=en">Xinchao Wang</a>.
</p>

<p>
His research interests include vision-and-language understanding, generative AI, and embodied AI.
</p>

<h2>Join Us</h2> 
<p>
I am actively seeking self-motivated Master students(MSC)/Research Assistants(RA, 有一定编程基础的本科生欢迎联系，到本实验室主导/参与研究工作，发表高质量论文) in AI.<br>
The research topics mainly include but are not limited to the following:
<ul>
  <li>Vision-and-Language Understanding</li>
  <li>Embodied AI</li>
  <li>Multimodal Large Language Model</li>
  <li>Large Language Model</li>
  <li>AI Safety</li>
</ul>
If you’re interested, please feel free to reach out via email (keji.he@sdu.edu.cn) with your curriculum vitae.   [英雄不问出处].
</p>
						

<h2> Selected Publications</h2> 
<ul>

<li><p><strong>Keji He*</strong>, Kehan Chen*, Jiawang Bai, Yan Huang, Qi Wu, Shu-Tao Xia, and Liang Wang, Everyday Object Meets Vision-and-Language Navigation Agent via Backdoor, <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2024. <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/58e6c003c9fb3992265005ff6aef1913-Paper-Conference.pdf" target="_self">PDF</a> </p></li>
<li><p><strong>Keji He</strong>, Ya Jing, Yan Huang, Zhihe Lu, Dong An, and Liang Wang, Memory-Adaptive Vision-and-Language Navigation, <i>Pattern Recognition (<strong>PR</strong>)</i>, 2024. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320324002620" target="_self">PDF</a> </p></li>
<li><p>Dong An, Hanqing Wang, Wenguan Wang, Zun Wang, Yan Huang, <strong>Keji He</strong>, and Liang Wang, Etpnav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>)</i>, 2024. <a href="https://arxiv.org/pdf/2304.03047" target="_self">PDF</a> </p></li>
<li><p><strong>Keji He</strong>, Chenyang Si, Zhihe Lu, Yan Huang, Liang Wang, and Xinchao Wang, Frequency-Enhanced Data Augmentation for Vision-and-Language Navigation, <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2023. <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/0d9e08f247ca7fbbfd5e50b7ff9cf357-Paper-Conference.pdf" target="_self">PDF</a> </p></li>
<li><p><strong>Keji He</strong>, Yan Huang, Qi Wu, Jianhua Yang, Dong An, Shuanglin Sima, and Liang Wang, Landmark-Rxr: Solving Vision-and-Language Navigation with Fine-Grained Alignment Supervision, <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2021. <a href="https://proceedings.neurips.cc/paper/2021/file/0602940f23884f782058efac46f64b0f-Paper.pdf" target="_self">PDF</a> </p></li>
</ul>
  

<h2>Competitions</h2> 
<ul>

  <table class="imgtable"><tr><td>
    <img src="assets/logos/ntire.png" alt="alt text" width="80" height="80" /> &nbsp;</td>
    <td align="left">
    <p> CVPR2024 New Trends in Image Restoration and Enhancement workshop and associated challenges (NTIRE). 
      Our team (Hongyuan Yu, Wan Cheng, Yuxin Hong, Binnan Han, Zhuoyuan Wu, Yajun Zou, Yuqing Liu, Jizhe Li, <b>Keji He</b>, Chao Fan, Heng Zhang, Xiaolin Zhang, Xuanwu Yin, Kunlong Zuo) is the <font color="#FF0000">champion</font> of Efficient Super-Resolution competition (Main-Track and Runtime). 
       See details here: <a href="https://cvlai.net/ntire/2024/">Results</a>.
    </p>
    </td></tr></table>

  <table class="imgtable"><tr><td>
    <img src="assets/logos/ijcai_challenge.png" alt="alt text" width="80" height="80" /> &nbsp;</td>
    <td align="left">
    <p> 1st Learning and Mining with Noisy Labels Challenge. Our team (Weichen Yu, Hongyuan Yu, Yan Huang, Dong An,
      <b>Keji He</b>, Zhipeng Zhang, Xiuchuan Li, Liang Wang) is the <font color="#FF0000">runner-up</font> of task 1-1 and <font color="#FF0000">2nd runner-up</font> of task 1-2. See details here: <a href="https://yuankaiqi.github.io/REVERIE_Chalhttp://ucsc-real.soe.ucsc.edu:1995/Competition.html">Results</a>.
    </p>
    </td></tr></table>
<!--
<table class="imgtable"><tr><td>
  <img src="assets/logos/robocup.png" alt="alt text" width="80" height="80" /> &nbsp;</td>
  <td align="left">
  <p> ROBOCUP JAPAN OPEN 2016. Our team ( Zhengdong Luo, Zihao An, Chengguang Xu, Fengting Li, Shuning Han, Yuanyuan Tong, Yanmei Jiao, <b>Hongyuan Yu</b>, Xiaotang Du) is the <font color="#FF0000">champion</font> of the task: Home and Simulation, the <font color="#FF0000">runner-up</font> of the task: Education. See details here: <a href="https://cc.nankai.edu.cn/2016/0405/c13291a147168/page.htm">Results of ROBOCUP JAPAN OPEN 2016</a>.
  </p>
  </td></tr></table>
-->

</ul> 
  
  
<h2> Professional Activities</h2> 
<ul>
<li><p>Chair, IEEE Student Branch, University of Chinese Academy of Sciences (2021-2022)</a></p></li>
<li><p>Reviewer, CVPR, ICCV, NeurIPS, ICML, ICLR, AAAI, ACM MM, PR, TMM, TCSVT, etc</p></li>
</ul>
  
  


<table width="100%"> 
	<tr> 
		<td align="center">&copy; Keji He | Last update: May 2025</td>
	</tr> 
</table>

</div>


</body>

</html>

