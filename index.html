

<!doctype html>
<html>

<head>


<title>Keji He</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Keji He, 何科技, CRIPAC, NLPR, CASIA, National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences, New Laboratory of Pattern Recognition, 人工智能全国重点实验室, State Key Laboratory of Multimodal Artificial Intelligence Systems"> 
<meta name="description" content="Keji He's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />

<script>
   function showPubs(id) {
  if (id == 0) {
    document.getElementById('pubs').innerHTML = document.getElementById('pubs_selected').innerHTML;
    document.getElementById('select0').style = 'text-decoration:underline;color:#000000';
    document.getElementById('select1').style = '';
  } else {
    document.getElementById('pubs').innerHTML = document.getElementById('pubs_by_topic').innerHTML;
    document.getElementById('select1').style = 'text-decoration:underline;color:#000000';
    document.getElementById('select0').style = '';
  }
}

</script>

</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Keji He 何科技<h1>
				</div>

                <h3>Assistant Professor</h3>

		<p>
                    School of Artificial Intelligence </br>
                    Shandong University </br>
					</br>
                    Email: keji.he@sdu.edu.cn </br>
		</p>
		<p>
			<!-- <a href="https://github.com/hongyuanyu"><img src="assets/logos/github_logo.png" height="30px"></a>&nbsp;&nbsp; -->
			<a href="https://scholar.google.com/citations?user=RHPI-NQAAAAJ&hl=zh-CN"><img src="assets/logos/google_logo.png" height="30px"></a>&nbsp;&nbsp;
			<!-- <a href="https://www.linkedin.com/in/hongyuan-yu-726126178/"><img src="assets/logos/linkedin_logo.png" height="30px"></a>&nbsp;&nbsp; -->
		</p>
			</td>

			</td>
			<td width="25%">
				<img src="assets/imgs/keji2.jpg" width="100%"/>
			</td>
		<tr>
	</tbody>
</table>

<h2>News</h2>
<ul>   
<li> <p>2024.12, One paper was published on NeurIPS 2024.</a> </p></li> 
<li> <p>2024.06, We won the CVPR2024 NTIRE Challenge on Efficient Super-Resolution competition (2 champions) and the related paper has been accepted by the CVPR2024 NTIRE.</a> </p></li> 
</ul>

<h2>Biography</h2> 
<p>
Dr. Keji He is an assistant professor at the School of Artificial Intelligence, Shandong University (SDU). He finished his PhD at the Institute of Automation, Chinese Academy of Sciences, supervised by Prof. <a href="https://scholar.google.com/citations?user=8kzzUboAAAAJ&hl=zh-CN">Liang Wang</a>  (IEEE Fellow) and Prof. <a href="https://yanrockhuang.github.io/">Yan Huang</a>. He is also a jointly PhD at the National University of Singapore (NUS), supervised by Prof. <a href="https://scholar.google.com/citations?user=w69Buq0AAAAJ&hl=en">Xinchao Wang</a>.
</p>

<p>
His research interests include vision-and-language understanding, generative AI, and embodied AI.
</p>

<h2>Join Us</h2> 
<p>
I am actively seeking self-motivated Master students(MSC)/Research Assistants(RA) in AI.<br>
The research topics mainly include but are not limited to the following:
<ul>
  <li>Vision-and-Language Understanding</li>
  <li>Embodied AI</li>
  <li>Multimodal Large Language Model</li>
  <li>Large Language Model</li>
  <li>AI Safety</li>
</ul>
If you’re interested, please feel free to reach out via email (keji.he@sdu.edu.cn) with your curriculum vitae.   [It's not where you come from, it's what you do that matters.].
</p>
						

<h2> Selected Publications</h2> 
<ul>

<li><p><strong>Keji He*</strong>, Kehan Chen*, Jiawang Bai, Yan Huang, Qi Wu, Shu-Tao Xia, and Liang Wang, Everyday Object Meets Vision-and-Language Navigation Agent via Backdoor, <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2024. <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/58e6c003c9fb3992265005ff6aef1913-Paper-Conference.pdf" target="_self">PDF</a> </p></li>
<li><p><strong>Keji He</strong>, Ya Jing, Yan Huang, Zhihe Lu, Dong An, and Liang Wang, Memory-Adaptive Vision-and-Language Navigation, <i>Pattern Recognition (<strong>PR</strong>)</i>, 2024. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320324002620" target="_self">PDF</a> </p></li>
<li><p>Dong An, Hanqing Wang, Wenguan Wang, Zun Wang, Yan Huang, <strong>Keji He</strong>, and Liang Wang, Etpnav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>)</i>, 2024. <a href="https://arxiv.org/pdf/2304.03047" target="_self">PDF</a> </p></li>
<li><p><strong>Keji He</strong>, Chenyang Si, Zhihe Lu, Yan Huang, Liang Wang, and Xinchao Wang, Frequency-Enhanced Data Augmentation for Vision-and-Language Navigation, <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2023. <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/0d9e08f247ca7fbbfd5e50b7ff9cf357-Paper-Conference.pdf" target="_self">PDF</a> </p></li>
<li><p><strong>Keji He</strong>, Yan Huang, Qi Wu, Jianhua Yang, Dong An, Shuanglin Sima, and Liang Wang, Landmark-Rxr: Solving Vision-and-Language Navigation with Fine-Grained Alignment Supervision, <i>Neural Information Processing Systems (<strong>NeurIPS</strong>)</i>, 2021. <a href="https://proceedings.neurips.cc/paper/2021/file/0602940f23884f782058efac46f64b0f-Paper.pdf" target="_self">PDF</a> </p></li>
</ul>
  

<h2>Competitions</h2> 
<ul>

  <table class="imgtable"><tr><td>
    <img src="assets/logos/ntire.png" alt="alt text" width="80" height="80" /> &nbsp;</td>
    <td align="left">
    <p> CVPR2024 New Trends in Image Restoration and Enhancement workshop and associated challenges (NTIRE). 
      Our team (<b>Hongyuan Yu</b>, Wan Cheng, Yuxin Hong, Binnan Han, Zhuoyuan Wu, Yajun Zou, Yuqing Liu, Jizhe Li, Keji He, Chao Fan, Heng Zhang, Xiaolin Zhang, Xuanwu Yin, Kunlong Zuo) is the <font color="#FF0000">champion</font> of Efficient Super-Resolution competition (Main-Track and Runtime). 
       See details here: <a href="https://cvlai.net/ntire/2024/">Results</a>.
    </p>
    </td></tr></table>

  <table class="imgtable"><tr><td>
    <img src="assets/logos/ijcai_challenge.png" alt="alt text" width="80" height="80" /> &nbsp;</td>
    <td align="left">
    <p> 1st Learning and Mining with Noisy Labels Challenge. Our team (Weichen Yu, <b>Hongyuan Yu</b>, Yan Huang, Dong An,
      Keji He, Zhipeng Zhang, Xiuchuan Li, Liang Wang) is the <font color="#FF0000">runner-up</font> of task 1-1 and <font color="#FF0000">2nd runner-up</font> of task 1-2. See details here: <a href="https://yuankaiqi.github.io/REVERIE_Chalhttp://ucsc-real.soe.ucsc.edu:1995/Competition.html">Results</a>.
    </p>
    </td></tr></table>
<!--
<table class="imgtable"><tr><td>
  <img src="assets/logos/robocup.png" alt="alt text" width="80" height="80" /> &nbsp;</td>
  <td align="left">
  <p> ROBOCUP JAPAN OPEN 2016. Our team ( Zhengdong Luo, Zihao An, Chengguang Xu, Fengting Li, Shuning Han, Yuanyuan Tong, Yanmei Jiao, <b>Hongyuan Yu</b>, Xiaotang Du) is the <font color="#FF0000">champion</font> of the task: Home and Simulation, the <font color="#FF0000">runner-up</font> of the task: Education. See details here: <a href="https://cc.nankai.edu.cn/2016/0405/c13291a147168/page.htm">Results of ROBOCUP JAPAN OPEN 2016</a>.
  </p>
  </td></tr></table>
-->

</ul> 
  
  
<h2> Professional Activities</h2> 
<ul>
<li><p>Chair, IEEE Student Branch, University of Chinese Academy of Sciences (2021-2022)</a></p></li>
<li><p>Reviewer, CVPR, ICCV, NeurIPS, ICML, ICLR, AAAI, ACM MM, PR, TMM, TCSVT, etc</p></li>
</ul>
  
  


<table width="100%"> 
	<tr> 
		<td align="center">&copy; Keji He | Last update: May 2025</td>
	</tr> 
</table>

</div>


</body>

</html>

